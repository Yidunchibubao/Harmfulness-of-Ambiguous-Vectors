{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7E9D8HzyXBcr3tIUaqA5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yidunchibubao/Harmfulness-of-Ambiguous-Vectors/blob/main/prepdata_procedure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upqurasoSVPO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip superwikt-fr.zip -d superwikt-fr"
      ],
      "metadata": {
        "id": "zokPuQTwS-CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "bmWkbv58Tg8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('superwikt-fr/superwikt-fr/2/SuperWikt-fr-coling2025/SuperWikt-fr-dbnary-dump-20230320.tsv', sep='\\t')\n",
        "df.head(20)"
      ],
      "metadata": {
        "id": "JSp3Ah6xUUOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"superwikt-fr/superwikt-fr/2/SuperWikt-fr-coling2025/README.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ovcEvmiFUkBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"superwikt-fr/superwikt-fr/2/SuperWikt-fr-coling2025/supersense_list.txt\", \"r\", encoding=\"utf-8\") as files_lists:\n",
        "   for line in files_lists:\n",
        "      print(line.strip())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tma5UvnuVryO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemma_to_supersense = {}\n",
        "lemma_to_hypersense = {}\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    lemma = row[\"lemma\"]\n",
        "    ss = row[\"supersense\"]\n",
        "    hs = row[\"hypersense\"]\n",
        "\n",
        "    if lemma not in lemma_to_supersense:\n",
        "        lemma_to_supersense[lemma] = set()\n",
        "    if pd.notna(ss):\n",
        "        lemma_to_supersense[lemma].add(ss)\n",
        "\n",
        "    if lemma not in lemma_to_hypersense:\n",
        "        lemma_to_hypersense[lemma] = set()\n",
        "    if pd.notna(hs):\n",
        "        lemma_to_hypersense[lemma].add(hs)\n",
        "\n",
        "lemma_to_supersense = {k: list(v) for k, v in lemma_to_supersense.items()}\n",
        "lemma_to_hypersense = {k: list(v) for k, v in lemma_to_hypersense.items()}"
      ],
      "metadata": {
        "id": "ytaUPj42WiyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemma_to_supersense.get(\"laveur\"))\n",
        "print(lemma_to_hypersense.get(\"laveur\"))"
      ],
      "metadata": {
        "id": "p2BoLtf9Q9Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(lemma_to_supersense.items())[:20]"
      ],
      "metadata": {
        "id": "wb6Oul7PZT-w",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(lemma_to_hypersense.items())[:20]"
      ],
      "metadata": {
        "id": "63ME1H-bZvCu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supersense_set = set(df[\"supersense\"].dropna().unique())\n",
        "hypersense_set = set(df[\"hypersense\"].dropna().unique())"
      ],
      "metadata": {
        "id": "P23QslPubetR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"supersense_set\", supersense_set)\n",
        "print(\"hypersense_set\", hypersense_set)"
      ],
      "metadata": {
        "id": "PdSlvUoaedtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(supersense_set))"
      ],
      "metadata": {
        "id": "XPM86i9genLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(hypersense_set))"
      ],
      "metadata": {
        "id": "G_e7enB0euou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordinateur = df[df[\"lemma\"] == \"ordinateur\"]"
      ],
      "metadata": {
        "id": "7DY4WGbXeycF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leur = df[df[\"lemma\"] == \"leur\"]\n",
        "print(leur)"
      ],
      "metadata": {
        "id": "_zWYT46c-29g",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ordinateur)"
      ],
      "metadata": {
        "id": "ZmY_RFzMgMGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ambiguous_sslemmas = []\n",
        "ambiguous_hslemmas = []\n",
        "for lemma, supersenses in lemma_to_supersense.items():\n",
        "    if len(supersenses) > 1:\n",
        "        ambiguous_sslemmas.append(lemma)\n",
        "\n",
        "for lemma, hypersenses in lemma_to_hypersense.items():\n",
        "    if len(hypersenses) > 1:\n",
        "        ambiguous_hslemmas.append(lemma)"
      ],
      "metadata": {
        "id": "FGTh0TobgODK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gh1jMTNHhTlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"lemmas with more than one supersense\")\n",
        "print(ambiguous_sslemmas)\n",
        "print(len(ambiguous_sslemmas))"
      ],
      "metadata": {
        "id": "tICrle2VhV0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VyaYkY6chw0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"lemmas with more than one hypersense\")\n",
        "print(ambiguous_hslemmas)\n",
        "print(len(ambiguous_hslemmas))"
      ],
      "metadata": {
        "id": "r1JD8OWGhzpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://zenodo.org/records/5975226/files/lemma-A-pos-bow.txt?download=1 -O lemma-A-pos-bow.txt"
      ],
      "metadata": {
        "id": "UBRn8aI6h8XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "words_bow =[]\n",
        "words2embeddings_bow = []\n",
        "\n",
        "with open(\"lemma-A-pos-bow.txt\", \"r\", encoding=\"utf-8\") as fs:\n",
        "    header = fs.readline().strip()\n",
        "    print(header)\n",
        "    vocab_size, vector_dim = map(int, header.split())\n",
        "\n",
        "    for line in fs:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        parts = line.split()\n",
        "        word = parts[0]\n",
        "        vector = [float(x) for x in parts[1:]]\n",
        "        words_bow.append(word)\n",
        "        words2embeddings_bow.append(vector)\n",
        "\n",
        "print(len(words_bow))\n",
        "print(len(words2embeddings_bow))"
      ],
      "metadata": {
        "id": "un2gjSTz_-U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_array_bow = np.array(words2embeddings_bow, dtype=float)\n",
        "print(embeddings_array_bow.shape)"
      ],
      "metadata": {
        "id": "xocxGtKlaagP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_bow.index(\"laveur_nom\"))\n",
        "print(embeddings_array_bow[28861])"
      ],
      "metadata": {
        "id": "6-UZjTBxACJ-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://zenodo.org/records/5975226/files/lemma-A-pos.txt?download=1\" -O lemma-A-pos.txt"
      ],
      "metadata": {
        "id": "35xepDtzCn63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "words2embeddings = []\n",
        "\n",
        "with open(\"lemma-A-pos.txt\", \"r\", encoding=\"utf-8\") as datas:\n",
        "  header = datas.readline().strip()\n",
        "  print(header)\n",
        "  vocab_size, vocab_dim = map(int, header.split())\n",
        "\n",
        "  for data in datas:\n",
        "        data = data.strip()\n",
        "        if not data:\n",
        "            continue\n",
        "        parts = data.split()\n",
        "        word = parts[0]\n",
        "        vector = [float(x) for x in parts[1:]]\n",
        "        words.append(word)\n",
        "        words2embeddings.append(vector)\n"
      ],
      "metadata": {
        "id": "EZjettrZEzKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_array = np.array(words2embeddings, dtype=float)\n",
        "print(embeddings_array.shape)"
      ],
      "metadata": {
        "id": "PSxCjXOAaHP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words.index(\"laveur_nom\"))"
      ],
      "metadata": {
        "id": "17WS4Q1gF4ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings_array[28861])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8mbI8k27LM_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "prep_data = {\n",
        "    'lemma_to_supersense': lemma_to_supersense, # dict of lemmas to supersenses\n",
        "    'lemma_to_hypersense': lemma_to_hypersense, # dict of lemmas to hypersenses\n",
        "    'supersense_set': supersense_set, # set: all supersenses\n",
        "    'hypersense_set': hypersense_set, # set: all hypersenses\n",
        "    'words': words, # list of str: words to embeddings\n",
        "    'embeddings': embeddings_array, # numpy array of list of list of floats: emdeddings to words\n",
        "    'words_bow': words_bow, # list of str: words to embeddings\n",
        "    'embeddings_bow': embeddings_array_bow, # numpy array of list of list of floats: emdeddings to words\n",
        "    'ambiguous_sslemmas': ambiguous_sslemmas, # list of str\n",
        "    'ambiguous_hslemmas': ambiguous_hslemmas  # list of str\n",
        "}\n",
        "\n",
        "with open('prep_data.pkl', 'wb') as f:\n",
        "    pickle.dump(prep_data, f)\n",
        "\n",
        "# one can also check these by using directly the .keys() method after the unpackage of this document"
      ],
      "metadata": {
        "id": "8_qTghcnHsx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('prep_data.pkl')"
      ],
      "metadata": {
        "id": "OMrU5DJpLhlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3TQRwqQLy3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkeXm9_pWhGf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}